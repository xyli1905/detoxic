{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "data_path = \"/Users/xyli1905/Projects/Datasets/Kaggle/QuoraToxicDetect/train.csv\"\n",
    "test_path = \"/Users/xyli1905/Projects/Datasets/Kaggle/QuoraToxicDetect/test.csv\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num of Label 0: 1225312 \n",
      " num of Label 1: 80810 \n",
      " Toxic percentage: 6.187017751787352 %\n"
     ]
    }
   ],
   "source": [
    "# data[\"target\"] to np array data_label\n",
    "data_label = np.array(data[\"target\"])\n",
    "#print(data_label)\n",
    "dist_dic = collections.Counter(data_label)\n",
    "print(\" num of Label 0: %s \\n num of Label 1: %s \\n Toxic percentage: %s %s\" \\\n",
    "      % (dist_dic[0], dist_dic[1], dist_dic[1]/(dist_dic[0] + dist_dic[1])*100., \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all text seq in data_seq for further processing\n",
    "seq_num = len(data)\n",
    "data_seq = list(data[\"question_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regular expressions for preprocessing\n",
    "import re\n",
    "\n",
    "# for latex math expression\n",
    "process_latex_expression = re.compile(\"(\\[math)((\\S|\\s)+?)(math\\])\")\n",
    "# for quotation\n",
    "process_quotation_single = re.compile(\"(\\s+|\\,\\.\\?|^)(\\')((\\s|\\S)+?)(\\')\")\n",
    "process_quotation_double1 = re.compile(\"(\\s+|\\,\\.\\?|^)(\\'\\')((\\s|\\S)+?)(\\'\\')\")\n",
    "process_quotation_double2 = re.compile(\"(\\s+|\\,\\.\\?|^)(\\\")((\\s|\\S)+?)(\\\")\")\n",
    "process_quotation_triple = re.compile(\"(\\s+|\\,\\.\\?|^)(\\'\\'\\')((\\s|\\S)+?)(\\'\\'\\')\")\n",
    "process_quotation_special = re.compile(\"(\\s+|\\,\\.\\?|^)(\\')((\\s|\\S)+?)(\\\")\")\n",
    "# for bracketed words\n",
    "process_bracketed_words  = re.compile(\"(\\s*|^)(\\()((\\s|\\S)+?)(\\))\")\n",
    "# for web address\n",
    "process_url_http = re.compile(\"(http|https)((\\S|\\s)+?)(\\s+|$)\")\n",
    "process_url_www = re.compile(\"(www)((\\S|\\s)+?)(\\s+|$)\")\n",
    "# for parallel words, \"/\" --> \"or\"\n",
    "process_double_parallel_words = re.compile(\"(\\s+|^)([A-Za-z\\-]+)(\\/)([A-Za-z\\-]+)(\\s+|[\\.\\?\\,\\!]|$)\")\n",
    "process_triple_parallel_words = re.compile(\"(\\s+|^)([A-Za-z\\-]+)(\\/)([A-Za-z\\-]+)(\\/)([A-Za-z\\-]+)(\\s+|[\\.\\?\\,\\!]|$)\")\n",
    "# for numbers 1231 2321.231 --> numbsymb\n",
    "process_number = re.compile(\"(\\s+|^)((\\d+\\.\\d+)|(\\d+))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RE_preprocessing(seq):\n",
    "    '''\n",
    "    note we use repr(\" \"+content[2])[1:-1] to turn the string into raw string\n",
    "    '''\n",
    "    # replace latex expression with standard symbol\n",
    "    seq = process_latex_expression.sub(\"latexmathexpression\", seq)\n",
    "\n",
    "    # replace web address: http(s):... or www. with standard symbol\n",
    "    seq = process_url_http.sub(\"webaddress \", seq)\n",
    "    seq = process_url_www.sub(\"webaddress \", seq)\n",
    "    \n",
    "    # check for quotations and delete ''' ''', '' '', ' ' or \" \" symbols\n",
    "    match = process_quotation_triple.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_triple.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "    \n",
    "    match = process_quotation_double1.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_double1.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "\n",
    "    match = process_quotation_single.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_single.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "        \n",
    "    match = process_quotation_double2.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_double2.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "        \n",
    "    match = process_quotation_special.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_special.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "        \n",
    "    # check for bracketed content and delete the brackets\n",
    "    match = process_bracketed_words.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_bracketed_words.sub(repr(\" \"+content[2])[1:-1], seq, 1)\n",
    "\n",
    "    # check parallel words, and replace \"/\" with \" or \"\n",
    "    match = process_triple_parallel_words.findall(seq)\n",
    "    for content in match:\n",
    "        contentstr = \" \" + content[1] + \" or \" + content[3] + \" or \" + content[5] + \" \" + content[-1]\n",
    "        seq = process_triple_parallel_words.sub(repr(contentstr)[1:-1], seq, 1)\n",
    "    \n",
    "    match = process_double_parallel_words.findall(seq)\n",
    "    for content in match:\n",
    "        contentstr = \" \" + content[1] + \" or \" + content[3] + \" \" + content[-1]\n",
    "        seq = process_double_parallel_words.sub(repr(contentstr)[1:-1], seq, 1)\n",
    "        \n",
    "    # replace number e.g. 99 or 99.99 as \"numbsymb\"\n",
    "    seq = process_number.sub(\" numbsymb\", seq)\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def RE_preprocessing_except(seq):\n",
    "    '''\n",
    "    note use this if repr(\" \"+content[2])[1:-1] raise an exception\n",
    "    '''\n",
    "    # replace latex expression with standard symbol\n",
    "    seq = process_latex_expression.sub(\"latexmathexpression\", seq)\n",
    "\n",
    "    # replace web address: http(s):... or www. with standard symbol\n",
    "    seq = process_url_http.sub(\"webaddress \", seq)\n",
    "    seq = process_url_www.sub(\"webaddress \", seq)\n",
    "    \n",
    "    # check for quotations and delete ''' ''', '' '', ' ' or \" \" symbols\n",
    "    match = process_quotation_triple.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_triple.sub(\" \"+content[2], seq, 1)\n",
    "    \n",
    "    match = process_quotation_double1.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_double1.sub(\" \"+content[2], seq, 1)\n",
    "\n",
    "    match = process_quotation_single.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_single.sub(\" \"+content[2], seq, 1)\n",
    "        \n",
    "    match = process_quotation_double2.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_double2.sub(\" \"+content[2], seq, 1)\n",
    "        \n",
    "    match = process_quotation_special.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_quotation_special.sub(\" \"+content[2], seq, 1)\n",
    "        \n",
    "    # check for bracketed content and delete the brackets\n",
    "    match = process_bracketed_words.findall(seq)\n",
    "    for content in match:\n",
    "        seq = process_bracketed_words.sub(\" \"+content[2], seq, 1)\n",
    "        \n",
    "    # check parallel words, and replace \"/\" with \" or \"\n",
    "    match = process_triple_parallel_words.findall(seq)\n",
    "    for content in match:\n",
    "        contentstr = \" \" + content[1] + \" or \" + content[3] + \" or \" + content[5] + \" \" + content[-1]\n",
    "        seq = process_triple_parallel_words.sub(contentstr, seq, 1)\n",
    "    \n",
    "    match = process_double_parallel_words.findall(seq)\n",
    "    for content in match:\n",
    "        contentstr = \" \" + content[1] + \" or \" + content[3] + \" \" + content[-1]\n",
    "        seq = process_double_parallel_words.sub(contentstr, seq, 1)\n",
    "        \n",
    "    # replace number e.g. 99 or 99.99 as \"numbsymb\"\n",
    "    seq = process_number.sub(\"numbsymb\", seq)\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for tokenizing each question is 165.0142102241516 (s)\n"
     ]
    }
   ],
   "source": [
    "# question tokenization for training data\n",
    "# delete stop word?\n",
    "t1 = time.time()\n",
    "data_token = []\n",
    "for i in range(seq_num):\n",
    "    data_seq[i] = data_seq[i].lower()\n",
    "    try:\n",
    "        data_seq[i] = RE_preprocessing(data_seq[i])\n",
    "        data_token.append(nltk.word_tokenize(data_seq[i]))\n",
    "    except:\n",
    "        try:\n",
    "            data_seq[i] = RE_preprocessing_except(data_seq[i])\n",
    "            data_token.append(nltk.word_tokenize(data_seq[i]))\n",
    "        except:\n",
    "            print(i)\n",
    "t2 = time.time()\n",
    "print(\"Time for tokenizing each question is %s (s)\" % (t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for getting vocabulary is 3.7075717449188232 (s)\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary from the traning + test data\n",
    "t1 = time.time()\n",
    "words = []\n",
    "for question in data_token:\n",
    "    for word in question:\n",
    "        words.append(word)\n",
    "vocab = sorted(set(words))\n",
    "t2 = time.time()\n",
    "print(\"Time for getting vocabulary is %s (s)\" % (t2-t1))\n",
    "#print(len(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227734 1306122\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab), len(data_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 227734 words in vocabulary\n",
      "['bambino', 'bambolim', 'bamboo', 'bamboozle', 'bamboozled', 'bamburgh', 'bamcef', 'bamdad', 'bame', 'bamec', 'bamenda', 'bamford', 'bamgkok', 'bamigo', 'bamk', 'bamm-bamm', 'bamnoli', 'bamoer', 'bams', 'bamu', 'ban', 'ban-us.com', 'bana', 'banach', 'banagalore', 'banagar', 'banaglandia', 'banaglore', 'banajiga', 'banake', 'banal', 'banalizes', 'banalore', 'banana', 'banana-shaped', 'bananacoin', 'bananagrams', 'bananan', 'bananas', 'bananatag', 'banans', 'banao', 'banapple', 'banaras', 'banarasi', 'banarasidas', 'banarjee', 'banarsi', 'banashankari', 'banasthali', 'banasthli', 'banasura', 'banat', 'banca', 'bancaire', 'bancassurance', 'banch', 'banchi', 'banco', 'bancomext', 'bancoop', 'bancor', 'bancorp', 'bancorporation', 'bancourt', 'bancroft', 'bancrofti', 'bancshares', 'band', 'band-aid', 'band-tailed', 'band2', 'banda', 'bandage', 'bandaged', 'bandages', 'bandai', 'bandaid', 'bandaids', 'bandana', 'bandanas', 'bandar', 'bandar-log', 'bandara', 'bandaranaike', 'bandarban', 'bandarq', 'bandcamp', 'bandcoot', 'bandeau', 'banded', 'bandel', 'bandemia', 'bander', 'bandera', 'banderas', 'bandh', 'bandha', 'bandham', 'bandhan', 'bandhi', 'bandhs', 'bandhup', 'bandicoot', 'bandicoots', 'bandicot', 'bandidos', 'bandied', 'banding', 'bandipur', 'bandish', 'bandishes', 'bandit', 'banditism', 'banditrants', 'banditry', 'bandits', 'bandjarmasin', 'bandler', 'bandmates', 'bando', 'bandobast', 'bandoneon', 'bandpage', 'bandpass', 'bandra', 'bandra-kurla', 'bandra-worli', 'bands', 'bandslam', 'bandstand', 'bandung', 'bandura', 'bandwagon', 'bandwagoners', 'bandwagons', 'bandwidth', 'bandwidths', 'bandwith', 'bandy', 'bane', 'bane.do', 'baned', 'baneerjee', 'baneful', 'banega', 'baner', 'banerjee', 'banerji', 'banes', 'banff', 'banfield', 'bang', 'bang+-', 'bang-for-your-buck', 'bang.is', 'banga', 'bangabandhu', 'bangabhumi', 'bangal', 'bangala', 'bangaladeshi', 'bangaldeshis', 'bangalesh', 'bangali', 'bangalis', 'bangalor', 'bangalore', 'bangalore-mangalore', 'bangalore-mysore', 'bangalore.is', 'bangalore.the', 'bangalore/', 'bangalorean', 'bangaloreans', 'bangalorenfor', 'bangaluru', 'bangaolre', 'bangar', 'bangda', 'banged', 'bangelore', 'banger', 'bangers', 'banggood', 'banggood.com', 'banging', 'bangka', 'bangkok', 'bangkokians', 'bangla', 'banglabesh', 'bangladesh', \"bangladesh'es\", 'bangladesh-israeli', 'bangladesh-mayanmar', 'bangladeshi', 'bangladeshis', 'bangladsh', 'banglaore', 'banglas', 'bangldesh', 'bangle', 'bangledeshi', 'bangles', 'bangli', 'banglidesh', 'banglore', 'bangluru', 'bangoli', 'bangood', 'bangor', 'bangs', 'bangsamoro', 'bangtan', 'bangtanbomb', 'bangui', 'bangulure', 'banguluru', 'banhladesh', 'banhon', 'bani', 'bani-israel', 'bania', 'banias', 'baniel', 'banihal.com', 'baning', 'banis', 'banish', 'banished', 'banishes', 'banishing', 'banishment', 'banister', 'banitsa', 'baniya', 'baniyans', 'baniyas', 'banjara', 'banjaras', 'banjarmasin', 'banjo', 'bank', 'bank-account', 'bank-card', 'bank-in-an-app', 'bank-related', 'bank..will', 'bank.incase', 'banka', 'bankable', 'bankaccount', 'bankai', 'bankatlantic', 'bankbazaar.com', 'bankbazzar', 'bankble', 'bankcard', 'bankcruptcy', 'banke', 'banked', 'banker', 'banker.what', 'bankera', 'bankers', 'bankersadda', 'bankexamstoday.com', 'bankfinancial', 'banki', 'bankig', 'bankim', 'banking', 'banking/', 'banking/fund', 'bankng', 'banknifty', 'banknote', 'banknotes', 'bankrate', 'bankroll', 'bankrolled', 'bankrolling', 'bankrupt', 'bankruptcies', 'bankruptcy', 'bankrupted', 'bankrupting', 'bankrupts', 'banks', 'banks/', 'banksters', 'banksy', 'bankura', 'banlangen', 'banlieues', 'banmalevotes', 'banmankhi', 'banmed', 'bann', 'banna', 'bannana', 'bannari', 'bannd', 'banned', 'bannee', 'banneker', 'banner', 'bannerbit', 'bannerghatta', 'bannerjea', 'bannerjee', 'bannerman', 'bannermen', 'banners', 'banning', 'banning-among', 'bannister', 'bannned', 'bannon', 'bannonism', 'bannu', 'bano', 'banon', 'banovina', 'banpocolypse', 'banque', 'banquet', 'banqueting', 'banquets', 'banquo', 'banruptcy', 'bans', 'bansal', 'banshankari', 'banshee', 'banshi', 'bansko', 'bansthali', 'bansuri', 'banswara', 'banta', 'bantala', 'bantam', 'bantamweight', 'bantayan', 'banten', 'banter', 'banter-', 'bantering', 'banters', 'bantham', 'banthas', 'banti', 'bants', 'bantu', 'bantuan', 'bantustan', 'banu', 'banwani\\u200b', 'banwarilal', 'banyak', 'banyan', 'banyas', 'banyumasan', 'banzeer', 'banzene', 'banzon', 'bao', 'baobab', 'baoding', 'baofeng', 'baoh', 'baonnerjo', 'baoshan', 'baout', 'baozi', 'bap', 'bape', 'baphomet', 'bapm', 'baptise', 'baptised', 'baptism', 'baptismal', 'baptisms', 'baptist', 'baptista', 'baptists', 'baptize', 'baptized', 'baptizing', 'bapu', 'bapuji', 'bapunagar', 'bapus', 'baq', 'baqa3', 'baqarah', 'baqee', 'bar', 'bar-22', 'bar-at-law', 'bar-code', 'bar-one', 'bar_lev', 'bara', 'baraat', 'barabanki', 'barabar', 'barabara', 'barabare', 'barabaric', 'barabbas', 'barack', 'barad-dur', 'baragwanath', 'barahat', 'baraheni', 'barahkhadi', 'baraily', 'barak', 'baraka', 'barakhamba', 'baralikadu', 'baramula', 'baranagar', 'barangay', 'baraq', 'barasamarpanam', 'barasat', 'barasingha', 'barat', 'barathanatyam', 'baratheon', 'baratheons', 'barathiyar', 'baratto', 'barazani', 'barb', 'barbados', 'barbae', 'barbara', 'barbarella', 'barbaresco', 'barbaria', 'barbarian', 'barbarianism', 'barbarians', 'barbaric', 'barbarik', 'barbarism', 'barbarossa', 'barbarous', 'barbary', 'barbasol', 'barbeau', 'barbecue', 'barbecued', 'barbecues', 'barbed', 'barbel', 'barbell', 'barbells', 'barbeque', 'barbeques', 'barbequing', 'barber', 'barbera', 'barbero', 'barbers', 'barbershop', 'barbershops', 'barbeu-dubourg', 'barbican', 'barbie', 'barbie.avi', 'barbieri', 'barbies', 'barbital', 'barbiturates', 'barbizon', 'barbona', 'barbosa', 'barbour', 'barboza', 'barbra', 'barbri', 'barbs', 'barbuda', 'barbudans', 'barc', 'barca', 'barcalona', 'barcamp', 'barcel', 'barcelona', 'barcelona-psg', 'barcelonas', 'barcelona\\u200b', 'barcelonians', 'barch', 'barchart', 'barchfromspadelhi', 'barclay', 'barclaycard', 'barclays', 'barcode', 'barcodes', 'barcoding', 'bard', 'barda', 'bardai', 'bardas', 'barded', 'bardeen', 'bardem', 'bardhaman', 'bardi', 'barding', 'bardo', 'bardock', 'bardot', 'bards', 'bardstown', 'bardugo', 'bardwaj', 'bare', 'bare-bones', 'bare-bottom', 'bare-chest', 'bare-chested', 'bare-handed', 'bare-knuckle', 'bare-metal', 'bare-minimum', 'bareback', 'barebone', 'barechest', 'bared', 'barefaced', 'barefoot', 'barefooted', 'barefooter', 'barehanded', 'barehandedly', 'bareilly', 'bareilly-bisalpur', 'bareknuckle', 'barelly', 'barelwi', 'barelwis', 'barely', 'barely-adequate', 'baremetrics', 'barenaked', 'barentsburg', 'barerians', 'baretta', 'barf', 'barfi', 'bargain', 'bargain/deal/bang-for-buck/special', 'bargained', 'bargaining', 'bargains', 'barge', 'barged', 'bargehassus', 'barges', 'barging', 'barhain', 'bari', 'bariatric', 'bariatu', 'baricco', 'barilium', 'bariloche', 'barin', 'baring', 'barisal', 'barisan', 'barista', 'baristas', 'barite', 'bariton', 'baritone', 'baritones', 'barium', 'bark', 'barka', 'barkat', 'barkati', 'barkatulla', 'barkatullah', 'barkdoll', 'barked', 'barkely', 'barker', 'barkha', 'barkhaa', 'barkina', 'barking', 'barkley', 'barklyas', 'barkmann', 'barks', 'barkur', 'bark…the', 'barlett', 'barley', 'barleycorn', 'barlow', 'barm', 'barmaids', 'barman', 'barmuda', 'barmy', 'barn', 'barnabas', 'barnacles', 'barnala', 'barnard', 'barnardo', 'barnasankar', 'barnbrook', 'barnegat', 'barner', 'barnes', 'barnes-hut', 'barnet', 'barnett', 'barney', 'barnier', 'barnoparichay', 'barns', 'barnsley', 'barnum', 'barnun', 'barnwal', 'barnyard', 'baro', 'baroclinic', 'baroda', 'barograph', 'barokas', 'barolo', 'barometer', 'barometers', 'barometric', 'baron', 'baron-cohen', 'baron-reid', 'baroness', 'baronet', 'baronetess', 'barong', 'baronies', 'barons', 'barony', 'baron–cohen', 'baroque', 'barosh', 'barot', 'barotropic', 'barpali', 'barpeta', 'barq', 'barqati', 'barques', 'barquisimeto', 'barr', 'barra', 'barrack', 'barrackpore', 'barracks', 'barracoon', 'barracuda', 'barracudas', 'barrage', 'barrages', 'barramundi', 'barranquila', 'barranquilla', 'barre', 'barred', 'barrel', 'barreled', 'barreling', 'barrels', 'barren', 'barrera', 'barret', 'barreto', 'barrett', 'barricade', 'barricaded', 'barricades', 'barrick', 'barrie', 'barrier', 'barriers', 'barries', 'barring', 'barringer', 'barrington', 'barrios', 'barris', 'barristan', 'barrister', 'barristers', 'barrix', 'barron', 'barrons', 'barros', 'barroso', 'barroux', 'barrow', 'barrowed', 'barrows', 'barrowton', 'barry', 'barrycenter', 'barrymore', 'bars', 'bars..was', 'bars/clubs/restaurants/other', 'barsha', 'barshi', 'barsi', 'barsottelli', 'barstard', 'barstow', 'bart', 'bartaman', 'bartanve', 'bartelle', 'bartemius', 'bartend', 'bartender', 'bartenders', 'bartending', 'barter', 'bartered', 'bartering', 'bartetzko', 'bartezko', 'barth', 'barth/mike', 'barthelemy', 'barthes', 'bartholin', 'bartholomew', 'bartholomäus', 'barthé', 'bartlesville', 'bartlett', 'bartok', 'bartollas', 'bartolo', 'bartolomeo', 'bartolomeu', 'bartomeu', 'barton', 'bartonella', 'bartram', 'barty', 'bartók', 'baruah', 'baruch', 'baruipur', 'barujibi', 'barun', 'barunga', 'baruto', 'barve', 'baryazm', 'barycenter', 'barycentre', 'barycentric', 'baryon', 'baryonic', 'baryons', 'baryonyx', 'baryshnikov', 'baryta', 'baryton', 'barz', 'barzani', 'barzilai', 'barça', 'bar…', 'bar…have', 'bas', 'bas-congo', 'bas-ess', 'basa', 'basal', 'basal-cell', 'basalt', 'basaltic', 'basant', 'basanthi', 'basanti', 'basar', 'basara', 'basavakalyan', 'basavanagudi', 'basavanna', 'basaveshwaranagar', 'basaveshwarnagar', 'basbar', 'basc', 'base', 'base+bonus+rsu', 'base-10', 'base-12', 'base-2', 'base-3', 'base-acid', 'base-building', 'base2/3', 'base20', 'base64', 'baseball', 'baseballer', 'baseballs', 'baseband', 'basebll', 'baseboard', 'baseboards', 'basecamp', 'based', 'basedstickman', 'basefont', 'basel', 'baseless', 'baseless.can', 'baselessly', 'baseline', 'baselining', 'baseload', 'baseman', 'basemen', 'basement', 'basements', 'basenji', 'basera', 'bases', 'basetao', 'basetball', 'basf', 'bash', 'bashar', 'bashar-al-assad', 'bashed', 'basheer', 'basher', 'bashers', 'bashes', 'bashful', 'bashing', 'bashings', 'bashir', 'bashirhat', 'bashkir', 'bashmasur', 'bashneft', 'basho', 'bashu', 'basic', 'basic+gp', 'basic.and', 'basic.if', 'basically', 'basicity', 'basicks', 'basicly', 'basics', 'basicslly', 'basidiomycota', 'basidium', 'basijis', 'basil', 'basilar', 'basile', 'basilica', 'basilisk', 'basilisks', 'basilone', 'basilosaurid', 'basin', 'basincs', 'basing', 'basinger', 'basingstoke', 'basins', 'basir', 'basirhat', 'basis', 'basist', 'bask', 'basker', 'basket', 'basketabll', 'basketbal', 'basketball', 'basketballcourt', 'basketballer', 'basketballers', 'basketballet', 'basketballs', 'baskets', 'baskin', 'baskin-robbins', 'basking', 'baskoro', 'baskue', 'basli', 'baslp', 'basmathi', 'basmati', 'basna', 'basni', 'baso4', 'basophil', 'basophils', 'basque', 'basques', 'basquetball', 'basquiat', 'basra', 'bass', 'bass-baritone', 'bassa', 'bassanio', 'bassano', 'bassel', 'basses', 'basset', 'bassett', 'basshead', 'bassi', 'bassiest', 'bassinet', 'bassis', 'bassist', 'bassists', 'bassline', 'basslines', 'bassnectar', 'basso', 'bassoon', 'basswood', 'bast', 'bastar', 'bastard', 'bastardised', 'bastardization', 'bastardize', 'bastardized', 'bastardizing', 'bastards', 'bastardy', 'baster', 'basterd', 'basterds', 'bastet', 'basti', 'bastian', 'bastiat', 'bastille', 'bastinado', 'bastion', 'bastions', 'bastogne', 'baston', 'bastoy', 'bastrop', 'bastyr', 'basu', 'basudde', 'basuke', 'basuki', 'basundi', 'baswan', 'baswana', 'baswedan', 'basys', 'basys2', 'basıbozuk', 'basıc', 'bat', 'bat-family', 'bat-like', 'bata', 'bataan', 'bataclan', 'bataille', 'batak']\n"
     ]
    }
   ],
   "source": [
    "# terms that are not defined in embedding will be mapped into a single embedding vector, e.g.\n",
    "# - unrecognized symbols\n",
    "# - characters in chinese & other languages\n",
    "#\n",
    "# NOTE the following were/will be preprocessed:\n",
    "# [] money (maybe not important?)\n",
    "# [] dates/time ?how?\n",
    "# [] general math expression ?how?\n",
    "# [x] numbers --> numbersymb (a preliminary preprocessing)\n",
    "# [x] web address / url --> webaddress\n",
    "# [x] latex math expressions --> latexmathexpression\n",
    "# [x] single/double quotation marks\n",
    "# [x] bracketed words\n",
    "# [x] split words connected by \"/\", substitute \"/\" with \" or \" (a preliminary preprocessing)\n",
    "#\n",
    "vocab_len = len(vocab)\n",
    "print(\"there are %s words in vocabulary\" % vocab_len)\n",
    "base = 21\n",
    "start = 1000 * base\n",
    "num = 1000\n",
    "print(vocab[start:start + num])\n",
    "# with open('vocab.txt', 'w') as f:\n",
    "#     for item in vocab:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"…how\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution of question len in preprocessed data_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max Question len is 806, \n",
      "whose idx is 522266\n",
      "\n",
      "in star trek numbsymb why did they :\n",
      "\n",
      "*spoilers*\n",
      "*spoilers*\n",
      "*spoilers*\n",
      "*spoilers* numbsymb)make warping look quite a bit like an hyperspace jump numbsymb)what in the world were those bright particles as soon as they jumped. numbsymb)why in the world did they make it possible for two entities to react in warp space in separate jumps. numbsymb)why did spock get emotions for this movie. numbsymb)what was the point of hiding the enterprise underwater. numbsymb)when they were intercepted by the dark ship, how come they reached earth when they were far away from her. i don't seem to remember the scene where they warp to earth. numbsymb)how did the ship enter earth's atmosphere when it wasnt even in orbit. numbsymb)when scotty opened the door of the black ship , how come pike and khan didn't slow down?\n",
      "['in', 'star', 'trek', 'numbsymb', 'why', 'did', 'they', ':', '*spoilers*', '*spoilers*', '*spoilers*', '*spoilers*', 'numbsymb', ')', 'make', 'warping', 'look', 'quite', 'a', 'bit', 'like', 'an', 'hyperspace', 'jump', 'numbsymb', ')', 'what', 'in', 'the', 'world', 'were', 'those', 'bright', 'particles', 'as', 'soon', 'as', 'they', 'jumped', '.', 'numbsymb', ')', 'why', 'in', 'the', 'world', 'did', 'they', 'make', 'it', 'possible', 'for', 'two', 'entities', 'to', 'react', 'in', 'warp', 'space', 'in', 'separate', 'jumps', '.', 'numbsymb', ')', 'why', 'did', 'spock', 'get', 'emotions', 'for', 'this', 'movie', '.', 'numbsymb', ')', 'what', 'was', 'the', 'point', 'of', 'hiding', 'the', 'enterprise', 'underwater', '.', 'numbsymb', ')', 'when', 'they', 'were', 'intercepted', 'by', 'the', 'dark', 'ship', ',', 'how', 'come', 'they', 'reached', 'earth', 'when', 'they', 'were', 'far', 'away', 'from', 'her', '.', 'i', 'do', \"n't\", 'seem', 'to', 'remember', 'the', 'scene', 'where', 'they', 'warp', 'to', 'earth', '.', 'numbsymb', ')', 'how', 'did', 'the', 'ship', 'enter', 'earth', \"'s\", 'atmosphere', 'when', 'it', 'wasnt', 'even', 'in', 'orbit', '.', 'numbsymb', ')', 'when', 'scotty', 'opened', 'the', 'door', 'of', 'the', 'black', 'ship', ',', 'how', 'come', 'pike', 'and', 'khan', 'did', \"n't\", 'slow', 'down', '?']\n"
     ]
    }
   ],
   "source": [
    "# the longest question in raw string form\n",
    "maxlen = 0\n",
    "for i in range(seq_num):\n",
    "    tmplen = len(data_seq[i])\n",
    "    if tmplen > maxlen:\n",
    "        maxidx = i\n",
    "        maxlen = tmplen\n",
    "print(\"max Question len is %s, \\nwhose idx is %s\\n\" % (maxlen, maxidx))\n",
    "print(data_seq[maxidx])\n",
    "print(data_token[maxidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 522266\n"
     ]
    }
   ],
   "source": [
    "def max_token_length(token):\n",
    "    maxl = 0\n",
    "    idxl = 0\n",
    "    for i in range(seq_num):\n",
    "        tmplen = len(token[i])\n",
    "        if tmplen > maxl:\n",
    "            idxl = i\n",
    "            maxl = tmplen\n",
    "    return maxl, idxl\n",
    "\n",
    "max_token_len, max_token_idx = max_token_length(data_token)\n",
    "print(max_token_len, max_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_token[522266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_QWords(token_list):\n",
    "    len_dist = np.zeros(max_token_len, dtype = np.int)\n",
    "    for i in range(seq_num):\n",
    "        len_dist[len(token_list[i])-1] += 1\n",
    "    \n",
    "    return len_dist\n",
    "token_len_dist = count_QWords(data_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     6     20     81   5967  21412  41856  72121 101222 117865 119703\n",
      " 113027  98633  84741  71647  60685  50685  42997  36569  31462  27180\n",
      "  23468  20453  18197  16396  14598  13093  11841  10543   9280   8101\n",
      "   7085   6269   5377   4642   3880   3562   3125   2829   2648   2468\n",
      "   2272   2156   2004   1872   1780   1671   1462   1250   1150    936\n",
      "    844    634    550    445    371    273    204    160    110     79\n",
      "     54     36     24      8     12     14      2      3      3      2\n",
      "      0      2      1      0      0      0      0      0      1      0\n",
      "      0      0      0      0      0      0      1      0      0      0\n",
      "      0      0      0      0      0      0      0      1      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of number of words in data_token\n",
    "plt.plot(token_len_dist)\n",
    "print(token_len_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#porcess_latex_expression1 = re.compile(\"(\\[math\\])((\\S|\\s)+?)(\\[/math\\])\")\n",
    "test_porcess_latex_expression = re.compile(\"(\\[math)((\\S|\\s)+?)(math\\])\")\n",
    "test_process_quotation_single = re.compile(\"(\\s+|^)(\\')((\\s|\\S)+?)(\\')\")\n",
    "test_process_quotation_double1 = re.compile(\"(\\s+|^)(\\'\\')((\\s|\\S)+?)(\\'\\')\")\n",
    "test_process_quotation_double2 = re.compile(\"(\\s+|^)(\\\")((\\s|\\S)+?)(\\\")\")\n",
    "test_process_bracketed_words  = re.compile(\"((\\s+|\\S)|^)(\\()((\\s|\\S)+?)(\\))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when they were intercepted by the dark ship, how come they reached earth when they were far away from her. (i don't seem to remember the scene where they warp to earth).\n"
     ]
    }
   ],
   "source": [
    "test_seq = \"when they were intercepted by the dark ship, how come they reached earth when they were far away from her. (i don't seem to remember the scene where they warp to earth).\"\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_seq = process_quotation_single.sub('',test_seq)\n",
    "# test_seq = process_quotation_double1.sub(\" test\", test_seq)\n",
    "# test_seq = process_quotation_double2.sub(\" test\", test_seq)\n",
    "# test_seq = process_bracketed_words.sub(\" test\", test_seq)\n",
    "\n",
    "# print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ', ' ', '(', \"i don't seem to remember the scene where they warp to earth\", 'h', ')')\n",
      "when they were intercepted by the dark ship, how come they reached earth when they were far away from her. i don't seem to remember the scene where they warp to earth.\n"
     ]
    }
   ],
   "source": [
    "vv = test_process_bracketed_words.findall(test_seq)\n",
    "for term in vv:\n",
    "    print(term)\n",
    "    test_seq = test_process_bracketed_words.sub(\" \" + term[3], test_seq, 1)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasf dasfas dffasd dafsdf dd\n"
     ]
    }
   ],
   "source": [
    "vv = test_process_quotation_single.findall(test_seq)\n",
    "for term in vv:\n",
    "    test_seq = test_process_quotation_single.sub(\" \" + term[2], test_seq, 1)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the opposite​ term for \"connection​ established\"​?\n",
      "(' ', '\"', 'connection\\u200b established', 'd', '\"')\n",
      "What is the opposite​ term for connection​ established​?\n",
      "What is the opposite​ term for connection​ established​?\n"
     ]
    }
   ],
   "source": [
    "test_seq = data_seq[620542]\n",
    "print(test_seq)\n",
    "\n",
    "#print(test_porcess_latex_expression.sub(\"latexmathexpression\", test_seq))\n",
    "\n",
    "vv = test_process_quotation_double2.findall(test_seq)\n",
    "for term in vv:\n",
    "    print(term)\n",
    "    test_seq = test_process_quotation_double2.sub(\" \" + term[2], test_seq, 1)\n",
    "print(test_seq)\n",
    "\n",
    "vv = test_process_bracketed_words.findall(test_seq)\n",
    "for term in vv:\n",
    "    print(term)\n",
    "    print(repr(\" \" + term[3])[1:-1])\n",
    "    test_seq = test_process_bracketed_words.sub(repr(\" \" + term[3])[1:-1], test_seq, 1)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https', ':', '//w3resource.com']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"https://w3resource.com\"\n",
    "nltk.word_tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Who are https://ant.isi.edu? https://ant.isi.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_porcess_url_http = re.compile(\"(http|https)((\\S|\\s)+?)(\\s+|$)\")\n",
    "test_porcess_url_www = re.compile(\"(www)((\\S|\\s)+?)(\\s+|$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are webaddress webaddress \n"
     ]
    }
   ],
   "source": [
    "test = test_porcess_url_http.sub(\"webaddress \", test)\n",
    "test = test_porcess_url_www.sub(\"webaddress \", test)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are the salaries of automobile/mechan-ical\n"
     ]
    }
   ],
   "source": [
    "test = \"Why are the salaries of automobile/mechan-ical\"\n",
    "nltk.word_tokenize(test)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_process_double_parallel_words = re.compile(\"(\\s+|^)([A-Za-z\\-]+)(\\/)([A-Za-z\\-]+)(\\s+|[\\.\\?\\,\\!]|$)\")\n",
    "test_process_triple_parallel_words = re.compile(\"(\\s+|^)([A-Za-z\\-]+)(\\/)([A-Za-z]+\\-)(\\/)([A-Za-z\\-]+)(\\s+|$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are the salaries of automobile/mechan-ical\n"
     ]
    }
   ],
   "source": [
    "vv = process_bracketed_words.findall(test)\n",
    "for term in vv:\n",
    "    print(term)\n",
    "    test = test_process_bracketed_words.sub(\" \" + term[2], test, 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 'automobile', '/', 'mechan-ical', '')]\n",
      "(' ', 'automobile', '/', 'mechan-ical', '')\n",
      "automobile mechan-ical \n",
      "Why are the salaries of automobile or mechan-ical \n"
     ]
    }
   ],
   "source": [
    "vv = test_process_double_parallel_words.findall(test)\n",
    "print(vv)\n",
    "\n",
    "for term in vv:\n",
    "    print(term)\n",
    "    print(term[1],term[3],term[-1])\n",
    "    test = test_process_double_parallel_words.sub(repr(\" \" + term[1] + \" or \" + term[3] + \" \" + term[-1])[1:-1], test, 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why senior employees (4-8 yr exp.) of service based company (Infy/Wipro/CTS) never motivate juniors to switch to product based company?\n"
     ]
    }
   ],
   "source": [
    "test = data_seq[1037]\n",
    "print(test)\n",
    "test_process_number = re.compile(\"((\\d+\\.\\d+)|(\\d+))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why senior employees (d -d  yr exp.) of service based company (Infy/Wipro/CTS) never motivate juniors to switch to product based company?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_process_number.sub(\"d \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't in the embedding?\n",
    "import os\n",
    "from torch.nn import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"/Users/xyli1905/Projects/embeddings/glove.6B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path, name=\"6B\", dim=50):\n",
    "    glove_name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
    "    glove_path = os.path.join(path, glove_name)\n",
    "    #print(glove_path)\n",
    "    #glove = pd.read_csv(glove_path, sep=\" \", header=None)\n",
    "    glove_file = open(glove_path, \"r\")\n",
    "    glove = {}\n",
    "    for line in glove_file.readlines():\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        glove[word] = embedding\n",
    "    return glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = loadGlove(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 50\n",
    "latex_math_emb = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "webaddress_emb = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "numbsymb_emb   = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "unknow_word_emb = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "def get_embedding(word):\n",
    "    try:\n",
    "        embedding = glove[word]\n",
    "    except:\n",
    "        if word == \"latexmathexpression\":\n",
    "            embedding = latex_math_emb\n",
    "        elif word == \"webaddress\":\n",
    "            embedding = webaddress_emb\n",
    "        elif word == \"numbsymb\":\n",
    "            embedding = numbsymb_emb\n",
    "        else:\n",
    "            print(\"key not included, use new value:\")\n",
    "            embedding = unknow_word_emb\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49282   0.34231   0.93662   0.86695   0.62261   0.014615 -0.62331\n",
      "  0.021383  0.25933   0.23695  -0.043837  0.65615  -0.1218    0.1839\n",
      "  0.72801  -0.57085  -0.99428  -0.76187   0.044481 -0.66478   0.35339\n",
      " -1.372    -0.70328   0.34372  -0.55958  -1.5715   -0.073208 -0.62584\n",
      "  0.20277  -1.1796    2.4812    0.55142   0.018541  0.2869    0.1141\n",
      "  0.60408   0.55863   0.13701  -0.33045  -1.3547    1.0943    0.07671\n",
      " -0.25892   0.7989   -0.14411  -0.34701   0.31202   0.186     0.85489\n",
      "  0.025597]\n"
     ]
    }
   ],
   "source": [
    "word = \"card\"\n",
    "embedding = get_embedding(word)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingLayer = Embedding(vocab_len, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
